{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Description\n",
        "\n",
        "##Preprocessed data taken from a study done by Nanyang Technological University Singapore\n",
        "\n",
        "https://arxiv.org/abs/2106.00613\n",
        "\n"
      ],
      "metadata": {
        "id": "n1BhYTkEBWGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset from Google Drive"
      ],
      "metadata": {
        "id": "zIeuz9nlW1Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tabulate import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "from keras import layers, Model\n",
        "from google.colab import files\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.metrics import AUC, Precision, Recall"
      ],
      "metadata": {
        "id": "u0nfoU2LoRkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQZoum1hWA6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97cab802-3cb0-4cd1-c696-5f0ef78309ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the .mat file on your Google Drive\n",
        "mat_file_path = '/content/drive/MyDrive/Capstone/dataset.mat'\n",
        "\n",
        "# Load the .mat file\n",
        "mat_data = loadmat(mat_file_path)\n"
      ],
      "metadata": {
        "id": "biwUOIfoXETP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Transformer Model"
      ],
      "metadata": {
        "id": "aImjGrNJaOme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_positional_encoding(seq_length, d_model):\n",
        "    position = np.arange(seq_length)[:, np.newaxis]\n",
        "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
        "    pos_enc = np.zeros((seq_length, d_model))\n",
        "    pos_enc[:, 0::2] = np.sin(position * div_term)\n",
        "    pos_enc[:, 1::2] = np.cos(position * div_term)\n",
        "    return tf.convert_to_tensor(pos_enc, dtype=tf.float32)\n",
        "\n",
        "class PositionalEncoding(layers.Layer):\n",
        "    def __init__(self, seq_length, d_model):\n",
        "        super().__init__()\n",
        "        self.pos_encoding = get_positional_encoding(seq_length, d_model)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding\n",
        "\n",
        "class FeedForward(layers.Layer):\n",
        "    def __init__(self, d_model, dff, name=\"feedforward\"):\n",
        "        super(FeedForward, self).__init__(name=name)\n",
        "        self.dense1 = layers.Dense(dff, activation='relu')\n",
        "        self.dense2 = layers.Dense(d_model)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        return x\n",
        "\n",
        "class EncoderLayer(layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1, name=\"encoder_layer\"):\n",
        "        super(EncoderLayer, self).__init__(name=name)\n",
        "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.ffn = FeedForward(d_model, dff)\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.mha(inputs, inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        output = self.layernorm2(out1 + ffn_output)\n",
        "        return output\n",
        "\n",
        "class EEGTransformer(Model):\n",
        "    def __init__(self, seq_length, d_model, num_heads, num_layers, num_classes, dff, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.conv1d = layers.Conv1D(d_model, kernel_size=10, padding='same', activation='relu')\n",
        "        self.positional_encoding = PositionalEncoding(seq_length, d_model)\n",
        "        self.encoder_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.global_average_pooling = layers.GlobalAveragePooling1D()\n",
        "        self.classification_layer = layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        x = self.positional_encoding(inputs)\n",
        "        x = self.conv1d(x)\n",
        "        for i in range(len(self.encoder_layers)):\n",
        "            x = self.encoder_layers[i](x, training)\n",
        "        x = self.dropout(x, training=training)\n",
        "        x = self.global_average_pooling(x)\n",
        "        output = self.classification_layer(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "LMyF6rbIZfjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split and Train the Data"
      ],
      "metadata": {
        "id": "CDJajAHGaRa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EEGsample = mat_data['EEGsample']\n",
        "subindex = mat_data['subindex']\n",
        "substate = mat_data['substate']\n",
        "\n"
      ],
      "metadata": {
        "id": "MnQS3V9qtffW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EEGsample.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP2Cxh80tneD",
        "outputId": "adebbd9b-84c6-4d02-983b-c0503f5760d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2022, 30, 384)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8uTQR0Zut_g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Initialize a DataFrame to store the results\n",
        "results_df = pd.DataFrame(columns=['Subject', 'Average Accuracy', 'Average Loss', 'Average F1 Score', 'Average AUC Score'])\n",
        "\n",
        "# Define the number of repeats and the number of folds\n",
        "n_repeats = 5\n",
        "n_splits = 5\n",
        "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=0, restore_best_weights=True)\n",
        "\n",
        "# Iterate through all patient IDs\n",
        "for patient_id in range(1, 12):  # Assuming there are 11 patients with IDs from 1 to 11\n",
        "    print(f\"Processing subject {patient_id}\")\n",
        "\n",
        "    # Extract data for the current patient\n",
        "    patient_mask = subindex == patient_id\n",
        "    X = EEGsample[np.squeeze(patient_mask)]\n",
        "    y = substate[np.squeeze(patient_mask)]\n",
        "\n",
        "    channel_indices = [24,27,28,29]\n",
        "    X_selected_channels = X[:, channel_indices, :]\n",
        "\n",
        "    X = np.transpose(X_selected_channels, (0, 2, 1))\n",
        "\n",
        "\n",
        "    X_tensor = tf.convert_to_tensor(X, dtype=tf.float32)\n",
        "    y_tensor = tf.convert_to_tensor(y, dtype=tf.int32)\n",
        "\n",
        "    # Initialize lists to store the fold accuracies, losses, F1 scores, and AUC scores\n",
        "    fold_accuracies = []\n",
        "    fold_losses = []\n",
        "    fold_f1_scores = []\n",
        "    fold_auc_scores = []\n",
        "\n",
        "    # Iterate through the repeats of the k-fold cross-validation\n",
        "    for train_index, test_index in rskf.split(X_tensor.numpy(), y_tensor.numpy()):\n",
        "\n",
        "        model = EEGTransformer(\n",
        "            seq_length=384,\n",
        "            d_model=4,\n",
        "            num_heads=8,\n",
        "            num_layers=4,\n",
        "            num_classes=2,\n",
        "            dff=128,\n",
        "            dropout_rate=0.3\n",
        "        )\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer=Adam(learning_rate=0.00008), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "        # Create the training and test sets\n",
        "        X_train, X_test = X_tensor.numpy()[train_index], X_tensor.numpy()[test_index]\n",
        "        y_train, y_test = y_tensor.numpy()[train_index], y_tensor.numpy()[test_index]\n",
        "\n",
        "        # Further split the training data into training (80%) and validation (20%) sets\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "        # Convert the numpy arrays back into tensors\n",
        "        X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "        y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
        "        X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
        "        y_val = tf.convert_to_tensor(y_val, dtype=tf.int32)\n",
        "        X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "        y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
        "\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(32)\n",
        "        test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(train_dataset, validation_data=val_dataset, epochs=100, verbose=0, callbacks=[early_stop])\n",
        "\n",
        "        # Evaluate the model on the test set\n",
        "        test_loss, test_accuracy = model.evaluate(test_dataset, verbose=0)\n",
        "\n",
        "        # Compute predictions for F1 and AUC scores for test data\n",
        "        y_pred_raw = model.predict(X_test, verbose=0)\n",
        "        y_pred = np.argmax(y_pred_raw, axis=-1)\n",
        "\n",
        "        # Compute F1 scores and AUC scores for test data\n",
        "        test_f1_score = f1_score(y_test, y_pred, average='weighted')\n",
        "        test_auc_score = roc_auc_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        # Append the accuracies and losses to their respective lists\n",
        "        fold_accuracies.append(test_accuracy)\n",
        "        fold_losses.append(test_loss)\n",
        "        fold_f1_scores.append(test_f1_score)\n",
        "        fold_auc_scores.append(test_auc_score)\n",
        "\n",
        "    # Compute the average accuracies and losses\n",
        "    avg_accuracy = np.mean(fold_accuracies)\n",
        "    avg_loss = np.mean(fold_losses)\n",
        "    avg_f1_score = np.mean(fold_f1_scores)\n",
        "    avg_auc_score = np.mean(fold_auc_scores)\n",
        "\n",
        "    # Add the results to the DataFrame (outside the channel loop)\n",
        "    results_df = results_df.append({\n",
        "        'Subject': patient_id,\n",
        "        'Average Accuracy': avg_accuracy,\n",
        "        'Average Loss': avg_loss,\n",
        "        'Average F1 Score': avg_f1_score,\n",
        "        'Average AUC Score': avg_auc_score\n",
        "    }, ignore_index=True)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(results_df)\n",
        "results_df.to_excel('results.xlsx', index=False)\n",
        "# Download the Excel file\n",
        "from google.colab import files\n",
        "files.download('results.xlsx')\n"
      ],
      "metadata": {
        "id": "Ysw1wU5QpEVQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b68a390-246a-497f-f1f2-6f40523dbd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ba31934a57d>:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ba31934a57d>:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ba31934a57d>:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ba31934a57d>:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ba31934a57d>:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ba31934a57d>:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ba31934a57d>:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ba31934a57d>:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ba31934a57d>:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ba31934a57d>:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 11\n",
            "    Subject  Average Accuracy  Average Loss  Average F1 Score  \\\n",
            "0       1.0          0.749815      0.536685          0.733488   \n",
            "1       2.0          0.619430      0.659216          0.574406   \n",
            "2       3.0          0.604000      0.654126          0.558287   \n",
            "3       4.0          0.602759      0.653635          0.562037   \n",
            "4       5.0          0.721434      0.540129          0.686612   \n",
            "5       6.0          0.824492      0.411900          0.815322   \n",
            "6       7.0          0.584286      0.673924          0.518093   \n",
            "7       8.0          0.702424      0.578693          0.678171   \n",
            "8       9.0          0.801147      0.443706          0.788114   \n",
            "9      10.0          0.756190      0.499018          0.726607   \n",
            "10     11.0          0.720831      0.523856          0.700743   \n",
            "\n",
            "    Average AUC Score  \n",
            "0            0.749825  \n",
            "1            0.621538  \n",
            "2            0.604000  \n",
            "3            0.600095  \n",
            "4            0.720830  \n",
            "5            0.823382  \n",
            "6            0.583636  \n",
            "7            0.703419  \n",
            "8            0.800867  \n",
            "9            0.756182  \n",
            "10           0.720277  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ba31934a57d>:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_662ecb6c-c337-4315-88f0-e20452535638\", \"results.xlsx\", 5636)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Yv8YbyRMtWgV",
        "outputId": "96ebd9ed-59fd-4aae-d6fa-c3024794589d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-03aa8bf0b74f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEEGsample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'EEGsample' is not defined"
          ]
        }
      ]
    }
  ]
}